{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import matplotlib\n",
    "import copy\n",
    "import os\n",
    "from matplotlib import pyplot as plot\n",
    "from s4d.utils import *\n",
    "from s4d.diar import Diar\n",
    "from s4d import viterbi, segmentation\n",
    "from s4d.clustering import hac_bic\n",
    "from sidekit.sidekit_io import init_logging\n",
    "from s4d.gui.dendrogram import plot_dendrogram\n",
    "from s4d.diar import Diar\n",
    "from s4d.utils import *\n",
    "from s4d import scoring\n",
    "from s4d.model_iv import ModelIV\n",
    "from sidekit.sidekit_io import *\n",
    "from sidekit.bosaris import IdMap, Scores\n",
    "from s4d.clustering.hac_iv import hac_iv\n",
    "from s4d import scoring\n",
    "import numpy as np\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglevel = logging.DEBUG\n",
    "init_logging(level=loglevel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting important directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show = 'ES2003a.Mix-Headset'\n",
    "dir = 'out-mfcc-with-vad-vit'\n",
    "#dir = 'out-mfcc-with-vad'\n",
    "#dir = 'out'\n",
    "wdir = os.path.join(dir, show)\n",
    "sdir = os.path.join(wdir, 'segments')\n",
    "pdir = os.path.join(wdir, 'plda')\n",
    "final_segments_dir = os.path.join(wdir, 'results')\n",
    "linear_bic_dir = os.path.join(wdir, 'linear.bic')\n",
    "bic_hac_dir = os.path.join(wdir, 'bic.hac')\n",
    "hac_iv_dir = os.path.join(wdir, 'hac.iv')\n",
    "results_vit_dir = os.path.join(wdir, 'results.vit')\n",
    "\n",
    "if not os.path.exists(wdir):\n",
    "    os.makedirs(wdir)\n",
    "if not os.path.exists(sdir):\n",
    "    os.makedirs(sdir)    \n",
    "if not os.path.exists(pdir):\n",
    "    os.makedirs(pdir)\n",
    "if not os.path.exists(final_segments_dir):\n",
    "    os.makedirs(final_segments_dir)\n",
    "if not os.path.exists(linear_bic_dir):\n",
    "    os.makedirs(linear_bic_dir)    \n",
    "if not os.path.exists(bic_hac_dir):\n",
    "    os.makedirs(bic_hac_dir)\n",
    "if not os.path.exists(hac_iv_dir):\n",
    "    os.makedirs(hac_iv_dir)\n",
    "if not os.path.exists(results_vit_dir):\n",
    "    os.makedirs(results_vit_dir)    \n",
    "    \n",
    "input_show = os.path.join('audio', show + '.wav')    \n",
    "segments_dir = 'segments'    \n",
    "plda_dir = 'plda'    \n",
    "data_dir = 'data'\n",
    "mfcc_dir = 'mfcc'\n",
    "idmap_fn = show + '.idmap.h5'\n",
    "model_fn = 'data/model/ester_model_1024_300_150.h5'\n",
    "hac_diar_fn = os.path.join(wdir, segments_dir, show + '.hac.{:.2f}.seg')\n",
    "score_fn = os.path.join(wdir, plda_dir, show + '.score.plda.h5') \n",
    "mfcc_fn = os.path.join(wdir, mfcc_dir, show + '.mfcc.h5')\n",
    "\n",
    "#Segmentation file's directories\n",
    "init_seg = os.path.join(wdir, segments_dir, 'init.seg')\n",
    "gd_seg = os.path.join(wdir, segments_dir, 'gd_seg_250.seg')\n",
    "linear_bic_seg = os.path.join(linear_bic_dir, 'li_bic.{:.2f}.seg')\n",
    "mfcc_m_speaker = os.path.join(wdir, mfcc_dir, show + '.{:.2f}.{:.2f}.test.mfcc.h5')\n",
    "bic_hac_seg = os.path.join(bic_hac_dir, 'bic_hac.{:.2f}.{:.2f}.seg')\n",
    "hac_iv_seg = os.path.join(final_segments_dir, 'bic_hac.{:.2f}.{:.2f}.{:.2f}.seg')\n",
    "results_vit_seg = os.path.join(results_vit_dir, 'bic_hac.{:.2f}.{:.2f}.{:.2f}.vit.-250.seg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading VAD and cepstral features with delta and double delta. Donot run if precomputed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = get_feature_extractor(input_show, type_feature_extractor='basic')\n",
    "fe.save(show, output_feature_filename=mfcc_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = get_feature_server(mfcc_fn, feature_server_type='sid')\n",
    "cep, _ = fs.load(show)\n",
    "cep[np.logical_not(_)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "win_size = 250\n",
    "\n",
    "#linear bic segmentation parameters\n",
    "#postive value of delta bic indicates we need two separate models for the adjacent segments. \n",
    "#Here we define the threshodls\n",
    "li_bic_p_start = .2\n",
    "li_bic_p_stop = 2.0\n",
    "li_bic_p_num = 10\n",
    "\n",
    "#bic hac threshold for merging clusters\n",
    "bic_hac_start = .5\n",
    "bic_hac_end = 3\n",
    "bic_hac_num = 10\n",
    "\n",
    "#hac_iv threshold\n",
    "t_min = -50\n",
    "t_max = 100\n",
    "t_num = 15\n",
    "\n",
    "vit_penalty = -250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###  Perform 3 layers of segmentation. Initial ( complete file is segmented), Gaussian divergence based segmentaion, followed by linear bic segmentation. ivectors are extracted and then clustered in the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_diar = segmentation.init_seg(cep, show)\n",
    "Diar.write_seg(init_seg, init_diar)\n",
    "gd_diar = segmentation.segmentation(cep, init_diar, win_size)\n",
    "Diar.write_seg(gd_seg, gd_diar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ToDo Add bic clustering followed by add more threshold for i-vector scoring. Store files in multiple formats\n",
    "#ToDo Make code multi-threaded and scalable for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_iv = ModelIV(model_fn)\n",
    "f = open('error.log', 'a+')\n",
    "counter = 0\n",
    "for t1 in np.linspace(li_bic_p_start, li_bic_p_stop, li_bic_p_num):\n",
    "    try:\n",
    "        # Loading Segmentations with varying thresholds\n",
    "        bicl_diar = segmentation.bic_linear(cep, gd_diar, t1, sr=False)\n",
    "        Diar.write_seg(linear_bic_seg.format(t1), bicl_diar)\n",
    "        \n",
    "        # Bic HAC\n",
    "        for bic_value in np.linspace(bic_hac_start, bic_hac_end, bic_hac_num):\n",
    "            bic = hac_bic.HAC_BIC(cep, bicl_diar, bic_value, sr=False)\n",
    "            bic_hac_diar = bic.perform(to_the_end=True)\n",
    "            Diar.write_seg(bic_hac_seg.format(t1, bic_value), bic_hac_diar)\n",
    "            vit_diar = viterbi.viterbi_decoding(cep, bic_hac_diar, vit_penalty)\n",
    "\n",
    "            # Extracting features per speaker\n",
    "            fe = get_feature_extractor(input_show, type_feature_extractor='sid')\n",
    "            idmap_bic = fe.save_multispeakers(bic_hac_diar.id_map(), \\\n",
    "                                              output_feature_filename=mfcc_m_speaker.format(t1, bic_value) \\\n",
    "                                              , keep_all=False)\n",
    "\n",
    "            # training i-vectors\n",
    "            fs = get_feature_server(mfcc_m_speaker.format(t1, bic_value), 'sid')\n",
    "            model_iv.train(fs, idmap_bic)\n",
    "            # Using plda to gather scores\n",
    "            distance = model_iv.score_plda_slow()\n",
    "            distance.write(score_fn)\n",
    "            scores = Scores(scores_file_name=score_fn)\n",
    "            #cep_vit, _ = fs.load(input_show, input_feature_filename=mfcc_m_speaker.format(t1, bic_value)) \n",
    "\n",
    "            # Using AHC on calculated scores\n",
    "            for hac_value in np.linspace(t_min, t_max, t_num):\n",
    "                diar_iv, _, _ = hac_iv(bic_hac_diar, scores, threshold=hac_value)\n",
    "                Diar.write_seg(hac_iv_seg.format(t1, bic_value, hac_value), diar_iv)\n",
    "                \n",
    "                #viterbi resegmentation\n",
    "                vit_diar = viterbi.viterbi_decoding(cep, diar_iv, vit_penalty)\n",
    "                Diar.write_seg(results_vit_seg.format(t1, bic_value, hac_value), vit_diar)\n",
    "                \n",
    "                \n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        counter += 1\n",
    "        f.write(str(e))\n",
    "        continue\n",
    "f.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute DER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyannote.core import PYANNOTE_URI, PYANNOTE_SEGMENT, PYANNOTE_LABEL, PYANNOTE_TRACK\n",
    "from pyannote.core import Annotation, Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mdtm_convert_to_annote(filename=None, flag='seg'):\n",
    "    cols = [PYANNOTE_TRACK, 'channel_no', PYANNOTE_SEGMENT,\\\n",
    "            'duration', 'speaker', 'trash1', 'trash2', PYANNOTE_LABEL]\n",
    "    #df = pd.read_csv(filename, header=None, sep=' ', names=cols)\n",
    "    if flag == 'seg':\n",
    "        df = Diar.read_seg(filename)\n",
    "    if flag == 'mdtm':\n",
    "        df = Diar.read_mdtm(filename)\n",
    "    temp_annotation = Annotation()\n",
    "    rate = .1\n",
    "    for row in df:\n",
    "        start = row['start']*rate\n",
    "        stop = row['stop']*rate\n",
    "        label = row['cluster']\n",
    "        filename = row['show']\n",
    "        #print(start, stop, label, filename)\n",
    "        temp_annotation[Segment(start, stop), filename] = label\n",
    "    return temp_annotation.copy()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.metrics.diarization import DiarizationErrorRate\n",
    "#result_dir = os.path.join(wdir, results_vit_dir)\n",
    "result_dir = results_vit_dir\n",
    "files = os.listdir(results_vit_dir)\n",
    "ref = mdtm_convert_to_annote('es2003a', 'mdtm')\n",
    "results = []\n",
    "for file_name in files:\n",
    "    result_file = os.path.join(result_dir, file_name)\n",
    "    hyp = mdtm_convert_to_annote(result_file, 'seg')\n",
    "    diarizationErrorRate = DiarizationErrorRate(skip_overlap=True, collar=.25)\n",
    "    der = diarizationErrorRate(ref, hyp, uem=Segment(0, 1139))\n",
    "    #print(\"DER = {0:.3f}\".format(der))\n",
    "    results.append(der)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results for feature type basic with feature type SID. 4000 experiments\n",
    "min(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results for feature type when SID. 1640 experiments\n",
    "min(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfect DER\n",
    "diarizationErrorRate = DiarizationErrorRate()\n",
    "der = diarizationErrorRate(ref, ref, uem=Segment(0, 1139))\n",
    "print(\"DER = {0:.3f}\".format(der))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
